# Ollama Configuration
# The base URL where Ollama is running (default: http://localhost:11434)
# If Ollama is running on a different server, update this URL accordingly
OLLAMA_BASE_URL=http://localhost:11434

# Ollama Model
# The default model to use for document summarization (default: deepseek-r1)
# Make sure this model is available in your Ollama installation
# You can check available models with: ollama list
OLLAMA_MODEL=deepseek-r1
